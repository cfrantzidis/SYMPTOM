{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b7982a-1b79-4431-ba74-68768fa217d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary) and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()  # Set the model to inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8751ad-d69b-4a54-b436-56da4ae32642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2119, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset from a txt file\n",
    "df = pd.read_csv('data3.txt', sep='\\t', quoting=3, engine='python', on_bad_lines='skip')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f9aad3-bbca-4393-8f0d-3c5746bc992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Stopwords and punctuation setup\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Clean text\n",
    "def clean_text(text):\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "df['Processed_Text'] = df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03edd2af-7155-4e4b-9e15-b37349397cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(text):\n",
    "    # Encode text using tokenizer\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    # Get output from BERT model\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    # Get embeddings from the last hidden state\n",
    "    embeddings = output.last_hidden_state[:, 0, :].squeeze().numpy()  # Taking the [CLS] token representation\n",
    "    return embeddings\n",
    "\n",
    "# Apply function to text data (may need to batch this operation depending on dataset size)\n",
    "df['bert_embeddings'] = df['Text'].apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e869f2-a433-4131-aefb-de2a8a5180cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(df['bert_embeddings'])\n",
    "y = df['Cause'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda4582-fd53-4d8b-8c1a-7226226b5643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 11520 candidates, totalling 115200 fits\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a more extensive parameter grid\n",
    "parameter_grid = {\n",
    "    'C': [0.1, 1, 2,3,4,5,6,7,8,9, 10,20,30,40,50, 100],  # Regularization parameter\n",
    "    'gamma': [0.001, 0.01, 0.1, 1,2,3,4,5,6,7,8,9,10, 'scale', 'auto'],  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Different types of kernels\n",
    "    'degree': [2, 3, 4,5,6,7],  # Degree of the polynomial kernel function (if 'poly' kernel is used)\n",
    "    'class_weight': [None, 'balanced']  # Use 'balanced' to adjust weights inversely proportional to class frequencies\n",
    "}\n",
    "\n",
    "svm_model = SVC()\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(svm_model, parameter_grid, cv=10, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd6812-612c-417a-a35a-4426db67cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM with the best parameters\n",
    "best_svm = SVC(**grid_search.best_params_)\n",
    "best_svm.fit(X_train, y_train)\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "# Performance report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0de897-c623-434c-a75b-b307375b4d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5ab22-2e5f-4463-a199-6035e6bd9745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
